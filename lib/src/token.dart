import 'package:token_parser/debug.dart';
import 'package:token_parser/token_parser.dart';
import 'package:token_parser/src/error.dart';
import 'package:token_parser/src/tokens/match.dart';
import 'package:token_parser/src/tokens/parent.dart';

class Token<LexemeT extends Lexeme> extends Match {
  /// The lexeme that generated this token, by matching.
  @override LexemeT pattern;
  
  /// The value of the input that matched the lexeme.
  @override String input;
  
  /// The start position of the token, from the input that matched the lexeme.
  @override int start;

  /// The end position of the token, from the input that matched the lexeme.
  @override int end;

  /// List of all the children tokens, shallow.
  /// 
  /// Contains the tokens that were generated by the children of this token's lexeme.
  final Set<Token> children;

  /// ## Token Parser - Token
  /// 
  /// A token is generated by a lexeme, as a result of tokenizing the input.
  /// 
  /// Represents a match of a lexeme against the input, with the context of the lexeme.
  /// Such as, the input, the start and end positions, and the lexeme that generated the token.
  ///
  /// ### Analyzing the Token Tree
  /// 
  /// You may use the parsed token to analyze the resulting tree,
  /// using the .get({ Lexeme? lexeme, String? name }) method will get all the tokens that match the lexeme or name.
  /// 
  /// The reach of the search can be limited by using the bool shallow argument,
  /// the default is false when having a lexeme or name, and true when no search parameters are given.
  /// 
  /// ```dart
  /// final result = grammar.parse('two words');
  /// 
  /// final words = result?.get(lexeme: word);
  /// final letters = result?.get(name: 'letter');
  /// 
  /// print('Words: ${ words?.map((token) => match.value) }');
  /// print('Letters: ${ letters?.get(letter).map((token) => match.value) }');
  /// ```
  Token(this.pattern, this.input, this.start, this.end, { Set<Token>? children }) :
    children = children ?? <Token>{}
  {
    if (lexeme.grammar is DebugGrammar) {
      (lexeme.grammar as DebugGrammar).tokenizing(lexeme, input, start);
    }
  }

  /// Creates a token that wraps a match.
  /// 
  /// This is useful when you want to create a token from a match,
  /// it will take the match's pattern, input, start and end.
  factory Token.match(LexemeT pattern, Match match) = TokenMatch;
  
  /// Creates a token that wraps a list of matches.
  /// 
  /// This is useful when you want to create a token from a list of matches,
  /// it will take the first match's pattern, input, start and last match's end.
  factory Token.matches(LexemeT pattern, Set<Token> matches) = TokenParent;
  
  /// Creates an empty token.
  /// 
  /// This is useful when you want to create a token that doesn't match anything,
  /// but still is not wrong, like for optional lexemes.
  factory Token.emptyAt(LexemeT pattern, String string, int start) =>
    Token(pattern, string, start, start);
  
  /// Throw a **LexicalSyntaxError** for a token that doesn't match.
  factory Token.mismatch(LexemeT pattern, String string, int start) =>
    throw LexicalSyntaxError(pattern, string, start);

  /* -= Match Methods =- */

  @override String? operator [](int group) => group == 0 ? value : null;
    
  @override String? group(int group) => this[group];
  @override List<String?> groups(List<int> groupIndices) => groupIndices.map(group).toList();
  @override int get groupCount => 0;

  /* -= Identification =- */

  /// The lexeme that generated this token, by matching.
  /// 
  /// Alternative to: `.pattern`
  LexemeT get lexeme => pattern;
  
  /// The name of the lexeme that generated this token.
  String? get name => lexeme.name;

  /// The value of the token matched by the lexeme.
  String get value => input.substring(start, end);
  
  /// The length of the token matched by the lexeme.
  int get length => end - start;

  /* -= Comparison =- */

  /// Checks if this token has the same position as another token.
  bool samePosition(Match other) =>
    start == other.start &&
    end == other.end;
    
  @override
  bool operator ==(Object other) =>
    other is Token &&
    lexeme == other.lexeme &&
    input == other.input &&
    samePosition(other);
    
  @override int get hashCode => Object.hash(lexeme, input, start, end);

  /* -= Analysis =- */

  /// List of all the children tokens, deeply. This contains all the children tokens of the children tokens.
  /// 
  /// Contains the tokens that were generated by the children of this token's lexeme,
  Set<Token> get allChildren => {
    ...children,
    ...children.expand((child) => child.allChildren)
  };

  /// Get all the tokens that match the lexeme or name, allows to analyze the resulting tree.
  /// 
  /// The reach of the search can be limited by using the `bool shallow` argument,
  /// the default is `false` when having a lexeme or name, and `true` when no search parameters are given.
  /// 
  /// ```dart
  /// final match = grammar.parse('two words');
  /// 
  /// final tokens = match.get();
  /// final words = match.get(lexeme: word);
  /// final letters = match.get(name: 'letter');
  /// ```
  Set<Token> get<T extends Lexeme>({ T? lexeme, String? name, bool? shallow }) {
    shallow ??= lexeme == null && name == null;
    return (shallow ? children : allChildren).whereType<Token>().where((child) {
      return child.lexeme is T &&
      (lexeme == null || child.lexeme == lexeme) &&
      (name == null || child.name == name);
    }
    ).toSet();
  }
}
